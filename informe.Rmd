---
title: "TP1"
author: "Grupo 6"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

\
Universidad Torcuato Di Tella

Licenciatura en Tecnología Digital\
**Tecnología Digital VI: Inteligencia Artificial**

# Trabajo Práctico 1

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introducción al Problema (1)

Para este trabajo práctico decidimos utilizar una base de datos compuesta por 32560 entradas de un censo realizado en Estados Unidos en el año 1994. En esta, se busca relacionar varios datos sobre cada individuo, como edad, sexo, nivel de educacion, etc. con el ingreso anual de estos mismos, midiendo si se encuentra por debajo o por arriba de USD \$50,000 dólares.

Pero, en esta instancia, decidimos abordar esta misma base de datos con otro angulo. Dado que el problema usual es predecir *income* dadas todas las variables predictoras, luego de comenzar con esta aproximacion al problema, decidimos que podiamos corrernos del camino conocido dando vuelta este problema.

¿Que si en vez de predecir el salario de una persona dadas sus características, pudiesemos predecir el sexo de la persona dado su salario y otras características?

Esto nos daría un mirada muy profunda sobre como estaban establecidos los roles de genero en el 1994 (cuando se recolectaron estos datos). Revelando así, como cada variable predictora impacta en la matriz que predice el genero de su combinación.

Esta misma base de datos se puede encontrar en: <https://archive.ics.uci.edu/dataset/2/adult>.

Para entender mejor esta base de datos, veamos las variables principales que la componen:\

### Variables Predictoras

***age***: la edad del individuo

-   Entero mayor a 0.

***workclass***: representa el estado laboral general del individuo

-   Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.

***fnlwgt***: cantidad de personas que el censo cree que representa ese registro

-   Entero mayor a 0.

***education***: el nivel educativo más alto alcanzado por el individuo

-   Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.

***education-num*****:** el nivel educativo en formato numérico

-   Entero mayor a 0.

***marital-status***: el estado civil del individuo. Married-civ-spouse se refiere a cónyuge civil y Married-AF-spouse a cónyuge de las Fuerzas Armadas.

-   Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.

***occupation*****:** tipo general de ocupación del individuo.

-   Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.

***relationship***: describe la relación de este individuo con otros en su hogar. Por ejemplo, puede ser esposo.

-   Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.

***race***: descripción de la raza del individuo.

-   White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.

***capital-gain***: ganancias de capital del individuo.

-   Entero mayor o igual a 0

***capital-loss***: pérdidas de capital del individuo.

-   Entero mayor o igual a 0.

***hours-per-week***: cantidad de horas trabajadas por semana según el individuo.

-   Continuo.

***native-country***: país de nacimiento del individuo.

-   United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinidad&Tobago, Peru, Hong, Holand-Netherlands.

***income***: indica si el individuo gana más o menos de \$50,000 dólares anuales

-   \<=50K, \>50K.

### Variable a Predecir:

***sex***: sexo biológico del individuo.

-   Male, Female.

Con esta base de datos, los árboles de decisión seran relativamente fáciles de interpretar y visualizar, lo que permite entender cómo las diferentes variables predictoras influyen en la predicción de si una persona es hombre o mujer.

Las características intrínsecas de nuestro conjunto de datos, como la combinación de variables categóricas y numéricas, la posible presencia de relaciones no lineales, y la necesidad de interpretabilidad hacen que el uso de árboles de decisión sea una elección justificada y adecuada para nuestro análisis de predicción de salarios.

## Observación de los Datos (2)

```{r}
library(readr)

# Cargamos el conjunto de datos original, aplicando la transformación correspondiente para marcar los valores faltantes como Na's.
datos = read_csv("adult.csv", na = "?", show_col_types = FALSE)

# Eliminamos las columnas que no utilizaremos.
datos <- subset(datos, select = -c(education, relationship))
summary(datos)
```

Para comenzar este analisis, debemos ajustar la base de datos en torno a lo que buscamos encontrar, eliminando variables predictoras repetidas, o que generen por si mismas una predicción obvia sobre lo que buscamos predecir. Por esto decidimos eliminar dos columnas:

1.  ***education:*** el nivel educativo más alto alcanzado por el individuo, expresado en un string.

    -   Dado que tambien tenemos la variable ***education-num***, que expresa lo mismo pero con un int en vez de string, decidimos eliminar la columna entera para evitar duplicados.

2.  ***relationship***: describe la relación de este individuo con otros en su hogar.

    -   Esta variable es un poco redundante con ***marital-status**,* ya que por mas que sus entradas son distntas la informacion que aportan es muy parecida, pero mas importantemente

A partir del summary podemos empezar a comprender la distribucion de los datos, podemos ver como los encuestados tienen edades entre los 17 y 90 años, con una edad promedio de 37. Pero con este simple analisis no podemos ver informacion compleja de nuestras variables, como por ejemplo la relacion que tiene la edad de una persona con su salario. Para esto, a continuación vamos a graficar estas relaciones con el fin de entender con mayor profundidad la incidencia que tienen las variables predictoras sobre nuestra variable a predecir.

```{r}
library(ggplot2)

ggplot(datos, aes(x = sex, y = age, fill = sex)) +
  geom_boxplot(alpha = 0.6) +
  labs(title = "Boxplot de Edad por Sexo",
       x = "Sexo",
       y = "Edad") +
  scale_y_continuous(breaks = seq(0, 100, 10)) +
  theme_minimal()
```

A simple vista podemos ver la distribucion etaria para ambos sexos, con la edad promedio de los hombres apenas mayor que la de las mujeres.

```{r}
ggplot(datos, aes(x = `education-num`, fill = sex)) +
  geom_bar(position = "fill", alpha = 0.8) +
  labs(
    title = "Proporción de Nivel Educativo por Sexo",
    x = "Nivel Educativo",
    y = "Proporción"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

En este gráfico podemos ver una clara diferencia entre la cantidad de mujeres y varones en todos los niveles de educación. En muchos, la cantidad de mujeres osila cerca de un cuarto en relacion a la cantidad de hombres que cumplieron ese nivel educativo.

```{r}
ggplot(datos, aes(x = sex, fill = income)) +
  geom_bar(alpha = 0.8, position = "fill") +
  labs(title = "Distribución de Ingreso por Sexo",
       x = "Sexo", y = "Proporción") +
  theme_minimal()
```

Al analizar el salario vemos como se sigue ampliando la brecha. En promedio, 1 de cada 3 hombres ganan mas de 50k al año, mientras que ese numero para las mujeres se acerca a 1 de cada 8.

```{r}
library(ggplot2)
library(scales)  # Para mostrar en %

ggplot(datos, aes(x = `hours-per-week`, fill = sex)) +
  geom_histogram(aes(y = after_stat(count / sum(count))),
                 position = "dodge", alpha = 0.6, bins = 20) +
  labs(title = "Horas Trabajadas por Semana según Sexo (Proporción)",
       x = "Horas por Semana", y = "Porcentaje") +
  scale_y_continuous(labels = percent) +
  scale_x_continuous(breaks = seq(0, 100, 10))
  theme_minimal()
```

Aquí tambien vemos una discrepancia, mientras que las mujeres dominan el mercado laboral en roles de menos de 40 horas semanales, a partir de ese numero, los hombres se llevan la delantera con margenes gigantescos.

## Árbol básico (3)

División datos, semilla

```{r}
set.seed(0)

# Obtenemos el total de filas que tiene nuestro dataset (32561)
n = nrow(datos)

# Elegimos de manera aleatoria los indices de la datos, asignando el 70% de los indices a los datos de entrenamiento, el 15% a datos de validación y 15% a datos de testeo

train_indices = sample(1:n, size = 0.7 * n)
remaining_indices = setdiff(1:n, train_indices)
val_indices = sample(remaining_indices, size = 0.15 * n)
test_indices = setdiff(remaining_indices, val_indices)

# Ahora creamos los datasets de train, validation y test, aleatorios, basados en los indices creados

train_set = datos[train_indices, ]
val_set = datos[val_indices, ]
test_set = datos[test_indices, ]
test_set_arbol = datos[test_indices, ]
```

Arbol default, valores default

```{r}
library(rpart)
library(rpart.plot)

arbol = rpart(formula = sex ~ ., data = train_set, method = "class")

# Calculamos la media del set de entrenamiento
mean_sex_train_set = mean(train_set$sex, na.rm = TRUE)
print(mean_sex_train_set)

rpart.plot(arbol, box.palette = "orange")

print(rpart.control())
```

\###*Análisis de los hiperparámetros*

Los hiperparámetros más relevantes y su valor por defecto en rpart son:

-   *minsplit* = 20 --\> Un nodo debe tener al menos 20 observaciones para ser considerado para una división, puede suceder como no.

-   *minbucket* = round(minsplit / 3) =\> 20/3 = 6.66 ≈ 7 --\> Por defecto, es aproximadamente un tercio de minsplit y limita el número mínimo de observaciones que debe tener un nodo terminal.

-   (complexity parameter) *cp* = 0.01--\> Controla la poda del árbol, en donde un valor de 0.01 significa que una división debe disminuir el error relativo en al menos un 1% para ser considerada. Un valor de 1 se corresponde con un árbol sin divisiones, mientras que un valor de 0, con un árbol de profundidad máxima. Sólo se agregan divisiones cuando el costo de agregarlas es menor al valor de *cp*.

-   *maxdepth* = 30 --\> un valor de 30 permite que el árbol tenga hasta 30 niveles de profundidad, este hiperparámetro controla la profundiad del mismo.

-   *xval* = 10 --\> una significación de 10 implica que se realizarán 10 validaciones cruzadas.

-   *maxcompete* = 4 --\> una estimación de 4 implica que retendrán las 4 mejores divisiones alternativas en cada nodo.

-   *maxsurrogate* = 5 --\> define el número máximo de variables sustitutas a retener en cada nodo. Las variables sustitutas se utilizan para manejar datos faltantes. Un valor de 5 significa que el algoritmo retendrá hasta 5 variables sustitutas por nodo.

-   *usesurrogate* = 2 --\> controla cómo se utilizan las variables sustitutas para manejar datos faltantes. Los valores posibles son:

    0 = No se utilizan variables sustitutas. 1 = Se utilizan variables sustitutas solo para dividir los datos. 2 = Se utilizan variables sustitutas tanto para dividir los datos como para asignar observaciones a nodos terminales.

-   *surrogatestyle* = 0 --\> define el estilo de selección de variables sustitutas. Los valores posibles son:

    0 = Se seleccionan las variables sustitutas basándose en la reducción del error. 1 = Se seleccionan las variables sustitutas basándose en la similitud con la variable principal.

```{r}
nrow(datos)
```

Comentario chamuyo final

## Evaluación (4)

Predecir con el modelo un poco

```{r}
# Predicciones de clase
predictions_class = predict(arbol, newdata = test_set, type = "class")

# Agregar las predicciones de clase al conjunto de datos
test_set$predicted_class_sex = predictions_class

# Predicciones de probabilidades
predictions_prob = predict(arbol, newdata = test_set, type = "prob")

# Agregar las predicciones de probabilidades al conjunto de datos
test_set$predicted_prob_sex = predictions_prob

message("Columnas 'predicted_class_sex' y 'predicted_prob_sex' agregadas exitosamente al dataset.")
```

Matriz de confusión

```{r}
library(caret)
library(recipes)
library(pheatmap)

generar_matriz_confusion = function(clase_real, clase_predicha){
  # Convertir las columnas a factores con los mismos niveles
  clase_real_factor = factor(clase_real, levels = c("Male","Female" ))
  clase_predicha_factor = factor(clase_predicha, levels = c("Male", "Female"))
  
  # Calcular la matriz de confusión
  matriz_confusion = confusionMatrix(clase_predicha_factor, clase_real_factor)
  
  # Extraer la tabla de la matriz de confusión
  cm = matriz_confusion$table
  
  # Calcular las longitudes positivas y negativas
  positive_len = sum(clase_real == "Female")
  negative_len = sum(clase_real == "Male")
  
  
  if (positive_len == 0 | negative_len == 0) {
  stop("No hay suficientes muestras de uno de los grupos para normalizar")
}

  # Normalizar la matriz de confusión
  cm[1, 1] = cm[1, 1] / negative_len
  cm[1, 2] = cm[1, 2] / positive_len
  cm[2, 1] = cm[2, 1] / negative_len
  cm[2, 2] = cm[2, 2] / positive_len
  
  pheatmap(cm,
           display_numbers = TRUE,
           color = colorRampPalette(c("coral", "orange"))(50),
           main = "Confusion Matrix",
           number_format = "%.2f",
           cluster_rows = FALSE,
           cluster_cols = FALSE,
           legend = TRUE,
           fontsize_number = 15)
  
  return(matriz_confusion)
}

# Llamar a la función con las columnas del dataset
matriz_de_confusion = generar_matriz_confusion(test_set$sex, test_set$predicted_class_sex)
```

Accuracy

```{r}
library(MLmetrics)

# Accuracy
accuracy = Accuracy(y_pred = test_set$predicted_class_sex, y_true = test_set$sex)
print(paste("Accuracy:", round(accuracy, 4)))

accuracy = matriz_de_confusion$overall['Accuracy']
print(accuracy)
```

PRecision y recall

```{r}
# Precision (Female como clase positiva)
precision = Precision(y_pred = test_set$predicted_class_sex, y_true = test_set$sex, positive = "Female")
print(precision)

# Recall (Female como clase positiva)
recall = Recall(y_pred = test_set$predicted_class_sex, y_true = test_set$sex, positive = "Female")
print(recall)

# Precision (Male como clase positiva)
precision = Precision(y_pred = test_set$predicted_class_sex, y_true = test_set$sex, positive = "Male")
print(precision)

# Recall (Male como clase positiva)
recall = Recall(y_pred = test_set$predicted_class_sex, y_true = test_set$sex, positive = "Male")
print(recall)

```

F1-score

```{r}
F1_Score(test_set$predicted_class_sex, y_true = test_set$sex, positive = "Female")
F1_Score(test_set$predicted_class_sex, y_true = test_set$sex, positive = "Male")
```

AUC ROC

```{r}
library(MLmetrics)
vector_sex <- ifelse(test_set$sex == "Male", 0, 1)
AUC(y_pred = test_set$predicted_prob_sex[,"Female"], y_true = vector_sex)

library(pROC)

# Plot ROC curve
roc_curve <- roc(vector_sex, test_set$predicted_prob_sex[, "Female"])

# Plot ROC curve
plot(roc_curve, main = "ROC Curve for Sex Prediction", col = "blue", lwd = 2)
```

Comentario chamuyo final

## Optimización del modelo(5)

maxdepth

```{r}
library(rBayesianOptimization)
library(rpart)
library(pROC)
library(ggplot2)

# Función para evaluar el rendimiento del árbol, con dataset como parámetro
evaluar_arbol = function(maxdepth, minsplit, minbucket, training, validation) {
  modelo = rpart(
    formula = sex ~ ., 
    data = training, 
    method = "class", 
    control = rpart.control(
      maxdepth = as.integer(maxdepth), 
      minsplit = as.integer(minsplit), 
      minbucket = as.integer(minbucket),
      cp = 0,
      xval = 0
    )
  )
  predicciones = predict(modelo, validation, type = "prob")[,2]
  roc_curve = roc(response = ifelse(validation$sex == "Female", 1, 0), predictor = predicciones)
  auc_score = auc(roc_curve)
  
  # Devolver una lista con el campo Score
  return(list(Score = auc_score))
}

# Definir los límites de los hiperparámetros
limites = list(
  maxdepth = c(1L, 30L), 
  minsplit = c(2L, 100L), 
  minbucket = c(1L, 10L)
)

# Ejecutar la optimización bayesiana
result = BayesianOptimization(
  FUN = function(maxdepth, minsplit, minbucket) {
    evaluar_arbol(maxdepth, minsplit, minbucket, train_set, val_set)
  },
  bounds = limites,
  init_points = 30,
  n_iter = 20,
)

graficar_performance = function(resultado){
  ggplot(resultado, aes(x = Round, y = Value)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Progreso del valor del area bajo la curva de AUC-ROC con OB",
       x = "Iteración",
       y = "Área Bajo la Curva de AUC-ROC") +
  theme_minimal()
}

# Extraer el historial de resultados
result_data = result$History

mejores_hiperparametros = result$Best_Par
```

minsplit

```{r}
graficar_performance(result_data)
```

minbucket

```{r}
# Función para evaluar el rendimiento del árbol, con dataset como parámetro
evaluar_arbol = function(maxdepth, minsplit, minbucket, training, validation) {
  modelo = rpart(
    formula = sex ~ ., 
    data = training, 
    method = "class", 
    control = rpart.control(
      maxdepth = as.integer(maxdepth), 
      minsplit = as.integer(minsplit), 
      minbucket = as.integer(minbucket),
      cp = 0,
      xval = 0
    )
  )
  predicciones = predict(modelo, validation, type = "prob")
  vector_sex_val <- ifelse(val_set$sex == "Male", 0, 1)
  auc_score = AUC(y_pred = predicciones[,"Female"], y_true = vector_sex_val)

  # Devolver una lista con el campo Score
  return(list(Score = auc_score))
}


```

```{r}
resultados_auc <- data.frame(MaxDepth = integer(), 
                             MinBucket = integer(), 
                             MinSplit = integer(),
                             AUC = numeric())

for (maxdepth in seq(1, 30, length.out = 10) |> round()) {
  for (minbucket in seq(1, 10, length.out = 5) |> round()) {
    for (minsplit in seq(0, 100, length.out = 10) |> round()){
      resultado <- evaluar_arbol(maxdepth = maxdepth, 
                                     minsplit = 20, 
                                     minbucket = minbucket, 
                                     training = train_set, 
                                     validation = val_set)
          
      resultados_auc <- rbind(resultados_auc, 
                              data.frame(MaxDepth = maxdepth, 
                                         MinBucket = minbucket, 
                                         MinSplit = minsplit,
                                         AUC = resultado$Score))
    }
  }
}
```

```{r}
library(plotly)

plot_ly(resultados_auc, 
        x = ~MaxDepth, 
        y = ~MinSplit, 
        z = ~MinBucket, 
        color = ~AUC, 
        type = "scatter3d", 
        mode = "markers", 
        text = ~paste("AUC: ", AUC)) %>%
  layout(title = "AUC vs Max Depth, Min Split y Min Bucket")
```

arbol con mejor performance en test análisis combinado

```{r}
plot(pressure)
```

comparacion con arbol basico y el optimo

```{r}
plot(pressure)
```

Comentario chamuyo final (y en cada caso, usar MUCHOS gráficos)

## Interpretación (6)

Comentar mejor y más prolijo lo anterior

## Valores faltantes (7)

generación de datasets nuevos

```{r}
contar_na_por_columna = function(df) {
  sapply(df, function(columna) sum(is.na(columna)))
}

generar_datos_na = function(dataset, porcentaje_na) {
  data_na = dataset
  cantidad_na = round(porcentaje_na * nrow(dataset))
  
  for (col in names(dataset)) {
    # Contar NAs actuales en la columna
    na_actuales = sum(is.na(data_na[[col]]))
    
    
    if (na_actuales < cantidad_na) {
      # Calcular cuántos NA faltan para llegar al porcentaje
      faltan = cantidad_na - na_actuales
      
      # Obtener solo las posiciones que no son NA
      disponibles = which(!is.na(data_na[[col]]))
      
      # Ajustar si faltan más de los disponibles
      if (faltan > length(disponibles)) {
        faltan = length(disponibles)
      }
      
      # Si hay disponibles, hacer el sample
      if (faltan > 0) {
        indices = sample(disponibles, faltan, replace = FALSE)
        data_na[[col]][indices] = NA
      }
    }
  }
  
  return(data_na)
}

print(contar_na_por_columna(datos))
newdsta =generar_datos_na(datos, 0.20)
print(contar_na_por_columna(newdsta))

```

nuevos arboles de decisiones (ES UNA BANDA OPTIMIZAR CADA UNO)

```{r}
# Creación de los nueve datasets
train_20_na = generar_datos_na(train_set, 0.20)
val_20_na = generar_datos_na(val_set, 0.20)
test_20_na = generar_datos_na(test_set, 0.20)

train_50_na = generar_datos_na(train_set, 0.50)
val_50_na = generar_datos_na(val_set, 0.50)
test_50_na = generar_datos_na(test_set, 0.50)

train_75_na = generar_datos_na(train_set, 0.75)
val_75_na = generar_datos_na(val_set, 0.75)
test_75_na = generar_datos_na(test_set, 0.75)
```

comparación con punto 5

```{r}
optimizar_arbol_grid <- function(train_set, val_set, limites) {
  # Generar todas las combinaciones posibles de hiperparámetros
  grid <- expand.grid(limites)

  resultados <- list()
  
  for (i in 1:nrow(grid)) {
    params <- grid[i, ]
    
    # Evaluar el árbol con los parámetros actuales
    score <- evaluar_arbol(
      maxdepth = params$maxdepth,
      minsplit = params$minsplit,
      minbucket = params$minbucket,
      train_set = train_set,
      val_set = val_set
    )
    
    resultados[[i]] <- c(params, score = score)
  }

  # Convertir la lista a data.frame
  resultados_df <- do.call(rbind, lapply(resultados, as.data.frame))

  # Elegir la combinación con mejor score
  mejor_modelo <- resultados_df[which.max(resultados_df$score), ]
  
  return(list(mejor_modelo = mejor_modelo, resultados = resultados_df))
}


crear_arbol = function(depth, split, bucket){
  nuevo_arbol = rpart(
  formula = sex ~ ., 
  data = train_20_na, 
  method = "class", 
  control = rpart.control(
    maxdepth = depth, 
    minsplit = split, 
    minbucket = bucket,
    cp = 0,
    xval = 0
  )
)
  
  nuevo_arbol
}
```

```{r}

# Buscamos hiperparametros óptimos para:

# 20% de los datos faltantes

result_20_NA = optimizar_arbol(train_20_na,val_20_na, 30,15)

result_data_20_NA = result_20_NA$History

best_hiper_20 = result_20_NA$Best_Par

# 50% de los datos faltantes

result_50_NA = optimizar_arbol(train_50_na,val_50_na, 30,15)

result_data_50_NA = result_50_NA$History

best_hiper_50 = result_50_NA$Best_Par

# 75% de lo datos faltantes

result_75_NA = optimizar_arbol(train_75_na,val_75_na, 30,15)

result_data_75_NA = result_75_NA$History

best_hiper_75 = result_75_NA$Best_Par

```


```{r}
# Ahora creamos los 3 modelos utilizando los hiperparametros encontrados

mejor_arbol_20_na = crear_arbol(best_hiper_20[1],best_hiper_20[2],best_hiper_20[3])

mejor_arbol_50_na = crear_arbol(best_hiper_50[1],best_hiper_50[2],best_hiper_50[3])

mejor_arbol_75_na = crear_arbol(best_hiper_75[1],best_hiper_75[2],best_hiper_75[3])

```


```{r}

predecir_y_calcular_score = function(arbol, set_test) {
  predicciones_modelo = predict(arbol, newdata = set_test, type = "prob")[,2]
  
  set_test$predicciones_optimas = predicciones_modelo
  set_test$predicciones_optimas = ifelse(set_test$predicciones_optimas >= 0.5, 1, 0)
  set_test$predicciones_optimas = as.factor(set_test$predicciones_optimas)
  
  curva_optimizada = roc(set_test$sex, predicciones_modelo)
  
  auc_score = auc(curva_optimizada)
  
  auc_score
}

# Predicciones y performance con el 20% de los datos faltantes

auc_score_20_NA = predecir_y_calcular_score(mejor_arbol_20_na,test_20_na)

curva_roc_20_NA = curva_AUC_ROC(test_20_na$predicted_class_sex, test_20_na$sex)

# Predicciones y performance con el 50% de los datos faltantes

auc_score_50_NA = predecir_y_calcular_score(mejor_arbol_50_na,test_50_na)

curva_roc_50_NA = curva_AUC_ROC(test_50_na$predicted_class_sex, test_50_na$sex)

# Predicciones y performance con el 75% de los datos faltantes

auc_score_75_NA = predecir_y_calcular_score(mejor_arbol_75_na,test_75_na)

curva_roc_75_NA = curva_AUC_ROC(test_75_na$predicted_class_sex, test_75_na$sex)

```


```{r}
graficar_curvas_ROC = function(curva_1, curva_2, titulo_1, titulo_2) {
  
  # Graficar la primera curva
  plot(curva_1$curva_roc, col = "blue", lwd = 3, main = "Curvas ROC", xlab = "Tasa de Falsos Positivos", ylab = "Tasa de Verdaderos Positivos")
  
  # Añadir la segunda curva al mismo gráfico
  lines(curva_2$curva_roc, col = "red", lwd = 3)
  
  # Añadir una leyenda para diferenciar las curvas
  legend("bottomright", legend = c(titulo_1, titulo_2), col = c("blue", "red"), lwd = 3)
  
  
}

```


```{r}

auc_score_mejor_arbol

auc_score_20_NA

graficar_curvas_ROC(curva_roc_20_NA, curva_optimizada, "Curva árbol 20% NA", "Curva árbol optimizado")

```


```{r}

auc_score_mejor_arbol

auc_score_50_NA

graficar_curvas_ROC(curva_roc_50_NA, curva_optimizada, "Curva árbol 50% NA", "Curva árbol optimizado")

```



```{r}

auc_score_mejor_arbol

auc_score_75_NA

graficar_curvas_ROC(curva_roc_75_NA, curva_optimizada, "Curva árbol 75 NA", "Curva árbol optimizado")

```


```{r}

auc_score_mejor_arbol

score_modelo_20_NA_con_set_completo = predecir_y_calcular_score(mejor_arbol_20_na,test_set)

score_modelo_50_NA_con_set_completo = predecir_y_calcular_score(mejor_arbol_50_na,test_set)

score_modelo_75_NA_con_set_completo = predecir_y_calcular_score(mejor_arbol_75_na,test_set)

```
Chamuyo final

## Conclusión (8)

Resumen de todas las secciones Efectividad del arbol Direcciones futuras (chamuyo)
